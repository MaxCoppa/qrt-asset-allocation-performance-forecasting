{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files & submission file for template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train.csv\", index_col=\"ROW_ID\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\", index_col=\"ROW_ID\")\n",
    "\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", index_col=\"ROW_ID\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\", index_col=\"ROW_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RET_features = [f\"RET_{i}\" for i in range(1, 20)]\n",
    "SIGNED_VOLUME_features = [f\"SIGNED_VOLUME_{i}\" for i in range(1, 20)]\n",
    "TURNOVER_features = [\"AVG_DAILY_TURNOVER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [3, 5, 10, 15, 20]:\n",
    "    X_train[f\"AVERAGE_PERF_{i}\"] = X_train[RET_features[:i]].mean(1)\n",
    "    X_train[f\"ALLOCATIONS_AVERAGE_PERF_{i}\"] = X_train.groupby(\"TS\")[\n",
    "        f\"AVERAGE_PERF_{i}\"\n",
    "    ].transform(\"mean\")\n",
    "\n",
    "    X_test[f\"AVERAGE_PERF_{i}\"] = X_test[RET_features[:i]].mean(1)\n",
    "    X_test[f\"ALLOCATIONS_AVERAGE_PERF_{i}\"] = X_test.groupby(\"TS\")[\n",
    "        f\"AVERAGE_PERF_{i}\"\n",
    "    ].transform(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = RET_features + SIGNED_VOLUME_features + TURNOVER_features\n",
    "features = features + [f\"AVERAGE_PERF_{i}\" for i in [3, 5, 10, 15, 20]]\n",
    "features = features + [f\"ALLOCATIONS_AVERAGE_PERF_{i}\" for i in [3, 5, 10, 15, 20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting one simple Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ridge = linear_model.Ridge(alpha=1e-2, fit_intercept=False)\n",
    "\n",
    "new_ridge.fit(X_train[features].to_numpy(na_value=0), y_train.to_numpy(na_value=0))\n",
    "\n",
    "preds_ridge = pd.DataFrame(\n",
    "    new_ridge.predict(X_test[features].fillna(0).to_numpy(na_value=0)),\n",
    "    index=sample_submission.index,\n",
    "    columns=[\"target\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (preds_ridge > 0).astype(int).to_csv(\"preds_ridge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a random forest using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 2**5,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": 40,\n",
    "}\n",
    "\n",
    "train_dates = X_train[\"TS\"].unique()\n",
    "test_dates = X_test[\"TS\"].unique()\n",
    "\n",
    "n_splits = 5\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "splits = KFold(n_splits=n_splits, random_state=0, shuffle=True).split(train_dates)\n",
    "\n",
    "for i, (local_train_dates_ids, local_test_dates_ids) in enumerate(splits):\n",
    "    local_train_dates = train_dates[local_train_dates_ids]\n",
    "    local_test_dates = train_dates[local_test_dates_ids]\n",
    "\n",
    "    local_train_ids = X_train[\"TS\"].isin(local_train_dates)\n",
    "    local_test_ids = X_train[\"TS\"].isin(local_test_dates)\n",
    "\n",
    "    X_local_train = X_train.loc[local_train_ids, features]\n",
    "    y_local_train = y_train.loc[local_train_ids, \"target\"]\n",
    "    X_local_test = X_train.loc[local_test_ids, features]\n",
    "    y_local_test = y_train.loc[local_test_ids, \"target\"]\n",
    "\n",
    "    X_local_train = X_local_train.fillna(0)\n",
    "    X_local_test = X_local_test.fillna(0)\n",
    "\n",
    "    model = RandomForestRegressor(**rf_params)\n",
    "    model.fit(X_local_train, y_local_train)\n",
    "\n",
    "    y_local_pred = model.predict(X_local_test)\n",
    "\n",
    "    models.append(model)\n",
    "    score = accuracy_score(\n",
    "        (y_local_test > 0).astype(int), (y_local_pred > 0).astype(int)\n",
    "    )\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {i+1} - Accuracy: {score* 100:.2f}%\")\n",
    "\n",
    "mean = np.mean(scores) * 100\n",
    "std = np.std(scores) * 100\n",
    "u = mean + std\n",
    "l = mean - std\n",
    "print(f\"Accuracy: {mean:.2f}% [{l:.2f} ; {u:.2f}] (+- {std:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    [model.feature_importances_ for model in models], columns=features\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.barplot(\n",
    "    data=feature_importances,\n",
    "    orient=\"h\",\n",
    "    order=feature_importances.mean().sort_values(ascending=False).index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params[\"random_state\"] = 0\n",
    "model = RandomForestRegressor(**rf_params)\n",
    "model.fit(X_train[features].fillna(0), y_train[\"target\"])\n",
    "preds_rf = model.predict(X_test[features].fillna(0))\n",
    "preds_rf = pd.DataFrame(preds_rf, index=sample_submission.index, columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (preds_rf > 0).astype(int).to_csv(\"preds_rf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a lightgbm using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quite large number of trees with low depth to prevent overfits\n",
    "lgbm_params = {\n",
    "    \"metric\": \"mse\",\n",
    "    \"num_threads\": 50,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"max_depth\": 5,\n",
    "}\n",
    "NUM_BOOST_ROUND = 100\n",
    "\n",
    "train_dates = X_train[\"TS\"].unique()\n",
    "test_dates = X_test[\"TS\"].unique()\n",
    "\n",
    "n_splits = 10\n",
    "scores_lgbm = []\n",
    "models_lgbm = []\n",
    "\n",
    "splits = KFold(\n",
    "    n_splits=n_splits,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ").split(train_dates)\n",
    "\n",
    "for i, (local_train_dates_ids, local_test_dates_ids) in enumerate(splits):\n",
    "    local_train_dates = train_dates[local_train_dates_ids]\n",
    "    local_test_dates = train_dates[local_test_dates_ids]\n",
    "\n",
    "    local_train_ids = X_train[\"TS\"].isin(local_train_dates)\n",
    "    local_test_ids = X_train[\"TS\"].isin(local_test_dates)\n",
    "\n",
    "    X_local_train = X_train.loc[local_train_ids, features]\n",
    "    y_local_train = y_train.loc[local_train_ids, \"target\"]\n",
    "    X_local_test = X_train.loc[local_test_ids, features]\n",
    "    y_local_test = y_train.loc[local_test_ids, \"target\"]\n",
    "\n",
    "    X_local_train = X_local_train\n",
    "    X_local_test = X_local_test\n",
    "\n",
    "    train_data = lgbm.Dataset(X_local_train, label=y_local_train.values)\n",
    "\n",
    "    model_lgbm = lgbm.train(lgbm_params, train_data, num_boost_round=NUM_BOOST_ROUND)\n",
    "\n",
    "    y_local_pred = model_lgbm.predict(\n",
    "        X_local_test.values, num_threads=lgbm_params[\"num_threads\"]\n",
    "    )\n",
    "\n",
    "    models_lgbm.append(model_lgbm)\n",
    "    score = accuracy_score(\n",
    "        (y_local_test > 0).astype(int), (y_local_pred > 0).astype(int)\n",
    "    )\n",
    "    scores_lgbm.append(score)\n",
    "    print(f\"Fold {i+1} - Accuracy: {score* 100:.2f}%\")\n",
    "\n",
    "mean = np.mean(scores_lgbm) * 100\n",
    "std = np.std(scores_lgbm) * 100\n",
    "u = mean + std\n",
    "l = mean - std\n",
    "print(f\"Accuracy: {mean:.2f}% [{l:.2f} ; {u:.2f}] (+- {std:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    [\n",
    "        model_lgbm.feature_importance(importance_type=\"gain\")\n",
    "        for model_lgbm in models_lgbm\n",
    "    ],\n",
    "    columns=features,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.barplot(\n",
    "    data=feature_importances,\n",
    "    orient=\"h\",\n",
    "    order=feature_importances.mean().sort_values(ascending=False).index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgbm.Dataset(X_train[features], label=y_train)\n",
    "model_lgbm = lgbm.train(lgbm_params, train_data, num_boost_round=NUM_BOOST_ROUND)\n",
    "preds_lgbm = model_lgbm.predict(X_test[features])\n",
    "preds_lgbm = pd.DataFrame(preds_lgbm, index=sample_submission.index, columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (preds_lgbm > 0).astype(int).to_csv(\"preds_lgbm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qupynt_ltdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
